{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96610611",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nf/lqj62v5n3pj50v8m9psrn48c0000gp/T/ipykernel_50907/2194453654.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[c].fillna(df[c].mean(), inplace=True)\n",
      "/var/folders/nf/lqj62v5n3pj50v8m9psrn48c0000gp/T/ipykernel_50907/2194453654.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[c].fillna('Unknown', inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RandomForest…\n",
      "RMSE (log): 0.37431227409534645\n",
      "R² (log): 0.7092571668892639\n"
     ]
    }
   ],
   "source": [
    "# ─────────── Imports (only once) ───────────\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "from rapidfuzz import process, fuzz\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection  import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble        import RandomForestRegressor\n",
    "from sklearn.metrics         import mean_squared_error, r2_score\n",
    "\n",
    "# ─────────── Load & Drop ───────────\n",
    "df = pd.read_csv(os.path.join(os.getcwd(), \"airbnbListingsData.csv\"))\n",
    "dropping_col = [ 'host_name',\n",
    " 'host_location',\n",
    " 'host_about',\n",
    " 'host_response_rate',\n",
    " 'host_acceptance_rate',\n",
    " 'host_total_listings_count',\n",
    " 'host_has_profile_pic',\n",
    " 'host_identity_verified',\n",
    " 'n_host_verifications',\n",
    " 'calculated_host_listings_count_entire_homes',\n",
    " 'calculated_host_listings_count_private_rooms',\n",
    " 'calculated_host_listings_count_shared_rooms', 'neighborhood_overview', 'name', 'description']\n",
    "df.drop(columns=dropping_col, errors='ignore', inplace=True)\n",
    "\n",
    "# ─────────── Missing Values ───────────\n",
    "#   object→'Unknown', numeric→mean\n",
    "for c in df.columns:\n",
    "    if df[c].dtype == 'object':\n",
    "        df[c].fillna('Unknown', inplace=True)\n",
    "    else:\n",
    "        df[c].fillna(df[c].mean(), inplace=True)\n",
    "\n",
    "# ─────────── Price & Log-Transform ───────────\n",
    "df['price'] = df['price'].replace('[\\$,]', '', regex=True).astype(float)\n",
    "df['log_price'] = np.log1p(df['price'])\n",
    "\n",
    "# ─────────── Amenities Normalize & Prune ───────────\n",
    "df['amenities'] = df['amenities'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else [])\n",
    "standard_amenities = {\n",
    "    'wifi': ['wifi', 'fast wifi'],\n",
    "    'tv': ['tv', 'hdtv', 'flat screen'],\n",
    "    'streaming_services': ['netflix', 'hbo max', 'amazon prime video', 'apple tv', 'chromecast', 'roku'],\n",
    "    'body_soap': ['body soap', 'bar soap', 'body wash'],\n",
    "    'shampoo': ['shampoo'],\n",
    "    'conditioner': ['conditioner'],\n",
    "    'sound_system': ['sound system', 'bluetooth sound system', 'speaker'],\n",
    "    'oven': ['oven', 'air fryer'],\n",
    "    'stove': ['stove', 'gas stove', 'electric stove'],\n",
    "    'workspace': ['workspace', 'monitor', 'desk', 'office chair'],\n",
    "    'refrigerator': ['refrigerator', 'fridge', 'mini fridge'],\n",
    "    'parking': ['parking', 'garage', 'driveway'],\n",
    "    'children_amenities': ['children', 'books and toys', 'crib', 'baby bath'],\n",
    "    'gym': ['gym', 'fitness'],\n",
    "    'pool': ['pool', 'rooftop pool', 'heated pool']\n",
    "}\n",
    "def normalize(a):\n",
    "    a = a.lower()\n",
    "    for cat, kws in standard_amenities.items():\n",
    "        match, score, _ = process.extractOne(a, kws, scorer=fuzz.partial_ratio) or (None, 0, None)\n",
    "        if score > 80:\n",
    "            return cat\n",
    "    return None\n",
    "\n",
    "df['norm_amenities'] = df['amenities'].apply(lambda L: {normalize(a) for a in L if normalize(a)})\n",
    "\n",
    "# Build binary columns for the 20 most common normalized amenities\n",
    "all_norms = set().union(*df['norm_amenities'])\n",
    "amen_df = pd.DataFrame([{n: int(n in norms) for n in all_norms} for norms in df['norm_amenities']])\n",
    "freq    = amen_df.sum().sort_values(ascending=False)\n",
    "top20   = freq.index[:20]\n",
    "amen_df = amen_df[top20]                            # keep just top 20\n",
    "df['amenity_count'] = amen_df.sum(axis=1)\n",
    "df = pd.concat([df, amen_df], axis=1)\n",
    "\n",
    "# ─────────── One-Hot & Boolean Encode ───────────\n",
    "df = pd.get_dummies(df, columns=['neighbourhood_group_cleansed','room_type'])\n",
    "bools = df.select_dtypes(include='bool').columns\n",
    "for b in bools:\n",
    "    df[b] = LabelEncoder().fit_transform(df[b])\n",
    "\n",
    "# ─────────── Final Cleanup ───────────\n",
    "# drop raw columns no longer needed\n",
    "df.drop(columns=['amenities','norm_amenities','price'], inplace=True)\n",
    "\n",
    "# ─────────── Train/Test Split & Model ───────────\n",
    "X = df.drop(columns='log_price')\n",
    "y = df['log_price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1234)\n",
    "\n",
    "\n",
    "\n",
    "# print(\"Training RandomForest…\")\n",
    "# rf = RandomForestRegressor(n_estimators=200, random_state=1234)\n",
    "# rf.fit(X_train, y_train)\n",
    "# preds = rf.predict(X_test)\n",
    "\n",
    "# print(\"RMSE (log):\", np.sqrt(mean_squared_error(y_test, preds)))\n",
    "# print(\"R² (log):\",  r2_score(y_test, preds))\n",
    "\n",
    "# ────────── Hyperparameter Tuning ──────────\n",
    "print(\"Tuning RandomForest…\")\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=RandomForestRegressor(random_state=1234),\n",
    "    param_grid=param_grid,\n",
    "    cv=3,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_rf = grid_search.best_estimator_\n",
    "preds = best_rf.predict(X_test)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"RMSE (log):\", np.sqrt(mean_squared_error(y_test, preds)))\n",
    "print(\"R² (log):\", r2_score(y_test, preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75c38aab",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid non-printable character U+00A0 (804399371.py, line 25)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[3], line 25\u001b[0;36m\u001b[0m\n\u001b[0;31m    idx = np.argsort(importances)[-20:]  # top 20\u001b[0m\n\u001b[0m                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid non-printable character U+00A0\n"
     ]
    }
   ],
   "source": [
    "### IMPORTS\n",
    "import matplotlib as plt\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "\n",
    "rf_preds = rf.predict(X_test)\n",
    "\n",
    "### ACTUAL VS PREDICTED ###\n",
    "print(\"ACTUAL VS PREDICTED\")\n",
    "plt.scatter(np.expm1(y_test), np.expm1(rf_preds), alpha=0.5)\n",
    "plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--')\n",
    "plt.xlabel(\"Actual Price ($)\")\n",
    "plt.ylabel(\"Predicted Price ($)\")\n",
    "plt.title(\"Actual vs. Predicted\")\n",
    "plt.show()\n",
    "\n",
    "### FEATURE IMPORTANCES ###\n",
    "\n",
    "print(\"FEATURE IMPORTANCES\")\n",
    "importances = rf.feature_importances_\n",
    "idx = np.argsort(importances)[-20:]  # top 20\n",
    "plt.barh(X.columns[idx], importances[idx])\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.title(\"Top 20 Feature Importances\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "### LEARNING CURVE ###\n",
    "print(\"LEARNING CURVE\")\n",
    "from sklearn.model_selection import learning_curve\n",
    "train_sizes, train_scores, val_scores = learning_curve(\n",
    "    rf, X, y, cv=5, scoring=\"neg_mean_squared_error\",\n",
    "    train_sizes=np.linspace(0.1, 1.0, 5), n_jobs=-1)\n",
    "train_rmse = np.sqrt(-train_scores.mean(axis=1))\n",
    "val_rmse   = np.sqrt(-val_scores.mean(axis=1))\n",
    "plt.plot(train_sizes, train_rmse, 'o-', label=\"Train\")\n",
    "plt.plot(train_sizes, val_rmse, 'o-', label=\"Validation\")\n",
    "plt.xlabel(\"Training Set Size\")\n",
    "plt.ylabel(\"RMSE (log-price)\")\n",
    "plt.legend()\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.show()\n",
    "\n",
    "### PRICE DISTRIBUTION BEFORE AND AFTER LOG ###\n",
    "print(\"PRICE DISTRIBUTION BEFORE AND AFTER LOG\")\n",
    "raw_price = np.expm1(df['log_price'])\n",
    "fig, axes = plt.subplots(1,2, figsize=(12,4))\n",
    "sns.histplot(raw_price, bins=50, kde=True, ax=axes[0]).set(title=\"Raw Price ($)\")\n",
    "sns.histplot(df['log_price'], ax=axes[1], bins=50, kde=True).set(title=\"Log-Transformed Price\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb9ebe8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.9.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
